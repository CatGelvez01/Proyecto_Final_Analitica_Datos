# ENTREGA FINAL ‚Äì CIENCIA DE DATOS APLICADA 

PROYECTO: ANAL√çSIS DE FLUJO VEHICULAR EN PEAJES COLOMBIANOS 

INTEGRANTES: 

* Nicolas Gonz√°lez Ochoa. 
* Francisco Santamar√≠a. 
* Ana Catalina Gelvez.

# üìä Link WEB APP 
https://p-gina-web-ciencia-de-datos.vercel.app/

‚ñ∂Ô∏è Explicaci√≥n WEB APP

El desarrollo del aplicativo combin√≥ un conjunto de lenguajes, librer√≠as y herramientas que permitieron llevar a cabo el an√°lisis de datos, la construcci√≥n del modelo de machine learning y la implementaci√≥n del dashboard interactivo para la visualizaci√≥n de resultados. A continuaci√≥n, se presenta el detalle de las tecnolog√≠as empleadas, clasificadas seg√∫n su prop√≥sito dentro del proyecto.
Los lenguajes de programaci√≥n usados fueron Python, el cual fue el lenguaje principal para: limpieza y transformaci√≥n de datos, an√°lisis exploratorio (EDA), ingenier√≠a de caracter√≠sticas, entrenamiento y validaci√≥n de modelos. Adem√°s de c√°lculo de m√©tricas y exportaci√≥n de modelos entrenados. Para el desarrollo del dashboard web interactivo se us√≥ JavaScript con el fin de Implementar la interfaz de usuario, visualizaci√≥n din√°mica de modelos y resultados. As√≠ mismo, la integraci√≥n con servicios de despliegue. 
Como parte del front end se utiliz√≥ HTML y CSS para construir la estructura de la p√°gina web, aplicaci√≥n de estilos, dise√±o y componentes visuales. Tambi√©n como soporte a la interfaz generada en React/Next.js

Finalmente, para el procesamiento y an√°lisis de datos se utilizaron diversas librer√≠as y frameworks de Python. Entre ellas, Pandas permiti√≥ el manejo de estructuras tabulares, as√≠ como la limpieza, filtrado y transformaci√≥n del dataset. En este proyecto tambi√©n se emple√≥ NumPy para brindar soporte num√©rico en operaciones vectorizadas y c√°lculos eficientes, y la librer√≠a Datetime para la manipulaci√≥n de fechas y secuencias temporales. Por otro lado, en la etapa de visualizaci√≥n se utilizaron Matplotlib para la generaci√≥n de gr√°ficos b√°sicos y anal√≠ticos, y Seaborn para la creaci√≥n de gr√°ficos estad√≠sticos y an√°lisis visual m√°s detallado.

El despliegue se efectu√≥ a trav√©s de la plataforma Vercel, que ofrece los servicios de alojamiento y servidores requeridos para poner en funcionamiento esta primera versi√≥n del aplicativo. Sin embargo, a futuro, el aplicativo podr√° migrar hacia una arquitectura en la nube que permite escalar de manera eficiente tanto el procesamiento de datos como la entrega de modelos y visualizaciones. Esta arquitectura podr√≠a basarse en servicios administrados que habiliten un flujo automatizado desde la ingesti√≥n y actualizaci√≥n del tr√°fico vehicular, hasta el entrenamiento, despliegue y monitoreo de los modelos de machine learning. Mediante servicios como almacenamiento en la nube para los datasets, contenedores o funciones serverless para la ejecuci√≥n de los modelos, y un servicio gestionado de bases de datos para los resultados procesados, el sistema podr√° operar con mayor estabilidad, seguridad y capacidad de respuesta. Adicionalmente, la integraci√≥n con plataformas de despliegue web permitir√° mantener el dashboard actualizado en tiempo real, ofreciendo una soluci√≥n completamente escalable y preparada para el crecimiento del negocio y el incremento en los vol√∫menes de datos.

‚òÅÔ∏è Futuro despliege serverless usando AWS 

A futuro, el aplicativo podr√° evolucionar hacia una arquitectura en la nube basada en AWS, permitiendo escalar de forma segura y eficiente el procesamiento de datos y la entrega de modelos predictivos. En este esquema, Amazon S3 servir√≠a como repositorio central para almacenar datasets hist√≥ricos y resultados procesados, mientras que AWS Lambda o Amazon ECS podr√≠an encargarse de ejecutar los modelos de machine learning de manera serverless o mediante contenedores escalables. Para la orquestaci√≥n del entrenamiento y actualizaci√≥n de modelos, AWS Step Functions y Amazon SageMaker ofrecer√≠an flujos automatizados y altamente gestionados. Los resultados del modelado podr√≠an almacenarse en Amazon RDS o DynamoDB, permitiendo consultas r√°pidas desde el dashboard. Finalmente, Amazon CloudFront y AWS Amplify, o un despliegue directo a trav√©s de AWS Elastic Beanstalk facilitan la entrega del aplicativo web con alto rendimiento y disponibilidad global. Esta arquitectura proporciona escalabilidad, tolerancia a fallos, costos optimizados por demanda y una base s√≥lida para integrar nuevas capacidades anal√≠ticas y productos de datos en el futuro.


# ‚ñ∂Ô∏è Repositorio Aplicativo WEB
https://github.com/Pacho2020095/P-ginaWebCienciaDeDatos


# üíª Presentaci√≥n 
[PresentacionProyectoFinal.pdf](https://github.com/user-attachments/files/23845025/PresentacionProyectoFinal.pdf)

# ‚èØÔ∏è Video presentaci√≥n 

Link al video:
* https://drive.google.com/drive/folders/1CXXS1VpRkqFW4Hx2e3w2K0O7njkHmEx3?usp=sharing
* https://uniandes-my.sharepoint.com/:v:/g/personal/ac_gelvez1783_uniandes_edu_co/IQDIykJ-U4uUQ507W69205avAakdEwFHbVaTb4YxdOPBRoI

# üìë PDF Documento 

[Entrega Final-Proyecto_AnalitcaDatos1 (1).pdf](https://github.com/user-attachments/files/23845258/Entrega.Final-Proyecto_AnalitcaDatos1.1.pdf)

# ‚ö†Ô∏è READ ME - Repositorio Modelos 

‚ñ∂Ô∏è IMPORTANTE 

Dado que el dataset excede el l√≠mite de 25 MB permitido por GitHub, no fue posible alojarlo en el repositorio. En su lugar, se ha habilitado un enlace a una carpeta de OneDrive, accesible para usuarios con correo institucional de la Universidad de los Andes, desde donde podr√°n descargar los archivos para su ejecuci√≥n local. 

Link al proyecto completo 
* https://uniandes-my.sharepoint.com/:f:/g/personal/ac_gelvez1783_uniandes_edu_co/IgC_NtThaH8ZToDHityGL7FUARKXvvbdXUn6ampmVEsA650?e=9Awf3A

# READ ME

üöß Descripci√≥n del Proyecto

Este repositorio contiene el desarrollo completo del proyecto de an√°lisis y modelado predictivo del tr√°fico vehicular para la Uni√≥n Temporal Peajes Nacionales (UTPN).
Incluye:

* An√°lisis exploratorio del comportamiento del tr√°fico.
* Procesamiento y limpieza del dataset.
* Entrenamiento de modelos de machine learning.
* Evaluaci√≥n de m√©tricas y desempe√±o.

Dashboard web para visualizar predicciones, errores y comportamiento del tr√°fico.

Documentaci√≥n t√©cnica, conclusiones de negocio y recomendaciones.

El objetivo principal del proyecto fue identificar oportunidades para optimizar los costos operativos de los peajes sin afectar su funcionamiento, utilizando modelos predictivos derivados de datos hist√≥ricos.

üéØ Objetivos del Proyecto

* Comprender los alcances y calidad del dataset disponible.
* Realizar an√°lisis exploratorio del tr√°fico por peaje y por sentido.
* Entrenar modelos predictivos que permitan anticipar el flujo vehicular.
* Determinar cu√°les carriles pueden ser desactivados sin afectar la operaci√≥n.
* Crear un dashboard para consulta, an√°lisis y toma de decisiones.
* Proponer conclusiones de negocio y oportunidades de mejora.

üß† Modelos de Machine Learning

Se entrenaron modelos independientes para cada peaje y cada sentido:

* Modelos utilizados
* DecisionTreeRegressor
* XGBoost Regressor (mejor desempe√±o general)
* M√©tricas implementadas
* RMSE
* MAE
* sMAPE
* MASE
* R¬≤

Los modelos permitieron identificar escenarios donde es posible optimizar hasta un 50% de los costos operativos, manteniendo la operaci√≥n sin afectaciones.

üìä Dashboard del Proyecto

El dashboard web muestra:

* Gr√°ficas de tr√°fico promedio por tipo de d√≠a.
* RMSE y m√©tricas de cada modelo entrenado.
+ Comparaci√≥n entre tr√°fico real y predicho.
* Selecci√≥n din√°mica de peajes y sentidos.
* Resumen general del desempe√±o de todos los modelos.
* Tecnolog√≠as del dashboard
* Next.js
* React
* Recharts / Chart.js
* Vercel (despliegue)

üßπ Procesamiento y Limpieza de Datos

El dataset fue procesado aplicando:

* Eliminaci√≥n de columnas irrelevantes o con m√°s del 70% de nulos.
* Manejo de duplicados.
* Revisi√≥n y correcci√≥n de formatos de fecha y hora.
* Normalizaci√≥n y codificaci√≥n de atributos categ√≥ricos.
* Selecci√≥n de atributos clave:
* Fecha
* Tr√°fico por sentido
* Tipo de d√≠a

Se trabaj√≥ con un dataset consolidado:
* 38.833 registros, 44 peajes, periodo entre 2022‚Äì2025.

‚öôÔ∏è Arquitectura T√©cnica (Actual y Futura)
Actual

Procesamiento y modelos: Python
* Visualizaci√≥n y uso: Dashboard en Next.js desplegado en Vercel

Distribuci√≥n del dataset: OneDrive (por l√≠mite de 25MB en GitHub)
* Futura arquitectura en AWS
* S3 para almacenamiento de datasets.
* Lambda / ECS para ejecuci√≥n de modelos.
* SageMaker para entrenamiento administrado.
* RDS o DynamoDB para almacenamiento de predicciones.
* CloudFront + Amplify para desplegar el dashboard.

üìÅ Estructura del Repositorio
/
‚îú‚îÄ‚îÄ notebooks/           # An√°lisis exploratorio y modelado (UTPN.ipynb)
‚îú‚îÄ‚îÄ models/              # Modelos entrenados (XGBoost / DecisionTree)
‚îú‚îÄ‚îÄ dashboard/           # C√≥digo del dashboard (Next.js)
‚îú‚îÄ‚îÄ diagrams/            # Diagramas del proyecto
‚îú‚îÄ‚îÄ data/                # Dataset (no incluido por l√≠mite de 25 MB)
‚îú‚îÄ‚îÄ utils/               # Funciones auxiliares
‚îî‚îÄ‚îÄ README.md

üîó Acceso al Dataset

El dataset no se incluy√≥ en el repositorio debido al l√≠mite de 25 MB impuesto por GitHub.
Ha sido habilitado en OneDrive para usuarios con correo institucional de la Universidad de los Andes.

üîó Enlace al dataset:
(agregar aqu√≠ cuando tengas el link)

ü§ù Contribuciones

Las contribuciones son bienvenidas a trav√©s de issues o pull requests.
Sugerencias de mejoras, optimizaciones o nuevos modelos son apreciadas.

üìÑ Licencia

Este proyecto se comparte bajo la licencia acordada con el cliente.
Modificar seg√∫n corresponda (MIT, Apache, Proprietary, etc.).

üß© Tecnolog√≠as y Librer√≠as Utilizadas

* Python
* Pandas
* NumPy
* Scikit-learn
* XGBoost
* Matplotlib
* Seaborn
* Joblib / Pickle
* Datetime


üìù Conclusiones

El proyecto demuestra el potencial del uso de datos y modelos predictivos para optimizar la operaci√≥n de peajes a nivel nacional. La implementaci√≥n de soluciones basadas en datos permite reducir costos, mejorar procesos y fortalecer la toma de decisiones estrat√©gicas.
Un desarrollo futuro puede incluir m√°s caracter√≠sticas, datos en tiempo real y despliegue en una arquitectura cloud completamente escalable.

# ‚ûï Edici√≥n extendida documento 

ENTREGA FINAL ‚Äì CIENCIA DE DATOS APLICADA 

PROYECTO: ANAL√çSIS DE FLUJO VEHICULAR EN PEAJES COLOMBIANOS 

INTEGRANTES: 

Nicolas Gonz√°lez Ochoa. 

Francisco Santamar√≠a. 

Ana Catalina Gelvez. 

INTRODUCCI√ìN 

...


PREPARACI√ìN DE DATOS 

En el notebook se implement√≥ un proceso estructurado de preparaci√≥n de datos previo al entrenamiento de los modelos. Este proceso inici√≥ con la lectura y consolidaci√≥n del dataset maestro, seguido de la normalizaci√≥n de tipos de datos y la estandarizaci√≥n del formato de fechas. Posteriormente, se elimin√≥ informaci√≥n irrelevante (como la columna de archivo original) y se reorganizaron las columnas clave: peaje, sentido_1, sentido_2, total y fecha. 

Para el tratamiento del ruido, se aplicaron funciones especializadas que recortan ceros al inicio y final de cada serie, evitando que valores no representativos afectaran los patrones temporales. Tambi√©n se implement√≥ la funci√≥n to_int_no_decimals, que garantiza que todos los valores de tr√°fico sean num√©ricos y consistentes, independientemente del formato original del archivo. 

Como parte de la ingenier√≠a de caracter√≠sticas, el notebook gener√≥ lags temporales, ventanas m√≥viles (rolling means), indicadores de calendario y variables ex√≥genas relevantes, con el fin de capturar la estacionalidad semanal y las tendencias del flujo vehicular. Asimismo, se aplic√≥ la funci√≥n slugify para normalizar los nombres de los peajes y evitar inconsistencias en el almacenamiento de modelos y resultados. 

Finalmente, se verific√≥ la integridad del dataset, imputando ceros o eliminando valores faltantes cuando fue necesario (siempre preservando la coherencia temporal). El resultado fue un conjunto de datos limpio, consistente y enriquecido, listo para ser usado tanto en el entrenamiento de los modelos como en la construcci√≥n de dashboards anal√≠ticos. 

 <img width="520" height="896" alt="Frame 1" src="https://github.com/user-attachments/assets/43936a48-0350-4298-b5ee-49dfd863fb59" />

 

ESTRATEGIA DE VALIDACI√ìN Y SELECCI√ìN DE MODELO 

Estrategia de validaci√≥n y selecci√≥n de modelo 

Para la construcci√≥n del producto de datos se defini√≥ una estrategia de experimentaci√≥n basada en series de tiempo, alineada con la naturaleza temporal del problema de predicci√≥n de flujo vehicular por peaje y sentido. 

Estrategia de experimentaci√≥n 

El experimento se plante√≥ a nivel de peaje y sentido, es decir, para cada estaci√≥n y para cada columna objetivo (sentido_1 y sentido_2) se entren√≥ un modelo independiente. Sobre cada serie se aplicaron las mismas etapas: 

Preparaci√≥n de datos: limpieza de registros inconsistentes, recorte de tramos con tr√°fico total igual a cero para evitar ruido, y generaci√≥n de caracter√≠sticas temporales como lags de 1, 3, 7, 14, 21 y 28 d√≠as, medias m√≥viles de 3, 7, 14 y 28 d√≠as, y variables calendarias. 

Modelos evaluados: se probaron tres algoritmos basados en √°rboles de decisi√≥n (XGBoost, LightGBM y CatBoost). Para XGBoost se realiz√≥ una b√∫squeda manual de hiperpar√°metros sobre una grilla de configuraciones, seleccionando la combinaci√≥n con menor RMSE en validaci√≥n. LightGBM y CatBoost se configuraron como modelos baseline avanzados y fueron comparados bajo las mismas m√©tricas. 

M√©tricas utilizadas: se emplearon RMSE, MAE, SMAPE y MASE. La selecci√≥n final del mejor modelo por peaje y sentido se bas√≥ principalmente en las m√©tricas de prueba (RMSE_test y MAE_test), complementadas con SMAPE y MASE para medir la precisi√≥n relativa y la mejora frente a un modelo na√Øve estacional. 

En la mayor√≠a de los casos, XGBoost result√≥ ser el modelo con mejor equilibrio entre precisi√≥n y estabilidad, por lo que fue seleccionado como algoritmo principal del producto de datos. 

Estrategia de partici√≥n: entrenamiento, validaci√≥n y prueba 

Dado que se trabaja con series de tiempo, se utiliz√≥ una partici√≥n estrictamente cronol√≥gica para evitar fugas de informaci√≥n (data leakage). Para cada peaje y sentido, los datos se ordenaron por fecha y se aplic√≥ una funci√≥n especializada que divide los datos en: 

Conjunto de prueba: los √∫ltimos 30 d√≠as de la serie. 

Conjunto de validaci√≥n: los 90 d√≠as anteriores al conjunto de prueba (o menos si la serie es corta). 

Conjunto de entrenamiento: todo el hist√≥rico anterior al conjunto de validaci√≥n. 

En series muy cortas, la funci√≥n ajusta din√°micamente los tama√±os para garantizar un entrenamiento m√≠nimo. Esta estrategia refleja adecuadamente el escenario real, donde el modelo aprende del pasado para predecir el futuro. 

Verificaci√≥n de la distribuci√≥n en los subconjuntos 

Para evaluar si los subconjuntos son representativos, se compararon estad√≠sticas como media, desviaci√≥n est√°ndar, percentiles y rangos de tr√°fico por sentido. Tambi√©n se verific√≥ la proporci√≥n de d√≠as entre semana y fines de semana. 

En la mayor√≠a de los peajes, las distribuciones se mantuvieron coherentes entre los subconjuntos, preservando la estacionalidad y la variabilidad natural. Sin embargo, en estaciones con cambios abruptos en comportamiento (como La Parada o Pto. Triunfo), los conjuntos de validaci√≥n y prueba mostraron mayor variabilidad, lo cual se reflej√≥ en mayores errores. Esto indica que para esos casos podr√≠an considerarse modelos m√°s flexibles o incluir informaci√≥n adicional sobre cambios operativos. 

En general, la estrategia de validaci√≥n implementada sigue las buenas pr√°cticas en series de tiempo y permite una evaluaci√≥n realista de la capacidad de generalizaci√≥n de los modelos. 

 

CONSTRUCCI√ìN Y EVALUACI√ìN DEL MODELO 

En el proceso de construcci√≥n y evaluaci√≥n del modelo se tuvo en cuenta los siguientes criterios de Selecci√≥n del Modelo Final.   

El modelo seleccionado para cada peaje/sentido fue aquel que cumpli√≥ con: 

Menor RMSE en el conjunto de prueba, el sMAPE estable y dentro de rangos aceptables (<20%). Adem√°s, el MASE < 1, indicando mejora sobre un modelo base y el comportamiento visual coherente en la comparaci√≥n real vs. Predicho. Por otro lado, la estabilidad entre validaci√≥n y prueba con estos criterios, el mejor desempe√±o identificado correspondi√≥ al peaje Bicentenario (Sentido 1) con un RMSE de prueba de 100.0. 

La estrategia integral de validaci√≥n y selecci√≥n garantiza que los modelos escogidos representen fielmente el comportamiento del tr√°fico, sean robustos frente a variaciones temporales, coherentes con las necesidades del cliente, igualmente, permitan tomar decisiones informadas sobre la operaci√≥n de los peajes. Finalmente, en conjunto, este proceso asegura el uso de modelos confiables, interpretables y con desempe√±o comprobado en escenarios reales.} 

Nota: Si se desea informaci√≥n m√°s detallada por favor visitar el repositorio en la secci√≥n del notebook UTPN.ipynb. 

RETROALIMENTACI√ìN POR PARTE DE LA ORGANIZACI√ìN 

 

A continuaci√≥n, se listan las interacciones hechas con los stakeholders 

ITEM 

FECHA 

STAKEHOLDER 

CARGO 

ACTIVIDAD 

1 

27/08/25 

Ger√≥nimo Canal 

Socio 1Solution (empresa socia de UTPN) 

hablar de la oportunidad que se presenta desde la materia en la cual se le muestra la oportunidad de crear un producto de datos que pueda aportar en la compa√±√≠a, el stakeholder consigue la cita con el gerente de peajes nacionales 

2 

27/08/25 

√Ålvaro Avenda√±o 

Gerente UTPN 

Se realiza un primer acercamiento con el gerente con el fin de acceder a una cita para comentar la oportunidad que se presenta, se agenda cita para el 28/08/2025 

3 

28/08/25 

Alvaro Avenda√±o 

Gerente UTPN 

Se realiza reunion presencial en la oficina de UTPN, en esta se le cuenta al stakeholder la oportunidad que se tiene de generar un producto de datos, se evidencian diferentes dolores entre los cuales estan, operaciones con costos fijos contractuales, PQRS y mantenimiento recurrente en estaciones. Se decide en conjunto avanzar con los costos fijos de operaci√≥n ya que se tienen datos. 

4 

8/09/25 

Alvaro Avenda√±o 

Gerente UTPN 

Se insiste al stakeholder en la entrega de informaci√≥n de datos. 

5 

9/09/25 

Alvaro Avenda√±o 

Gerente UTPN 

Se insiste al stakeholder en la entrega de informaci√≥n de datos, se indica que la persona encargada sera Carlos Guarin gerente financiero.  

6 

11/09/25 

Carlos Guarin  

Gerente financiero UTPN 

Se hace primer contacto con el stakeholder donde se le comenta la necesaidad de la informaci√≥n 

7 

12/09/25 

Carlos Guarin  

Gerente financiero UTPN 

Se realiza aclaraci√≥n de dudas sonre la informaci√≥n requerida  

8 

17-30/09/2025 

Carlos Guarin  

Gerente financiero UTPN 

Se realiza seguimiento para entrega de la informaci√≥n 

9 

6/10/25 

Carlos Guarin  

Gerente financiero UTPN 

Se remite informacion por parte del stakeholder 

10 

7/10/25 

Carlos Guarin  

Gerente financiero UTPN 

Se confirma al stakeholder que ya se descargo la informaci√≥n y se solicitan aclaraciones, donde indica lo progresivo de la informaci√≥n 

11 

16/10/25 

Carlos Guarin  

Gerente financiero UTPN 

Se le cuenta cual es el plan de implementaci√≥n al stakeholder  

12 

22/10/25 

Carlos Guarin  

Gerente financiero UTPN 

Se realiza un avance al stakeholder donde se muestra el analisis de informaci√≥n y basado en esto se realiza una selecci√≥n de estaciones objetivos 

13 

4/11/25 

Carlos Guarin  

Gerente financiero UTPN 

Se realiza avance al stakeholder y se realizan preguntas sobre el tiempo de transitos en carriles, se remtie un nuevo stakeholder que es el gerente de operaciones 

14 

19/11/25 

Cristina Duran 

Gerente operaciones 

Se habla con el stakeholder para indagar por el tiempo promedio de un vehiculo en transitar  

15 

25/11/25 

Carlos Guarin  

Gerente financiero UTPN 

Remite informaci√≥n de costos promedio por carril en cada estaci√≥n 

 

CONCLUSIONES 

¬øSe cumplieron los objetivos del proyecto? 

El prop√≥sito central del proyecto consisti√≥ en encontrar alternativas que permitieran reducir los costos operativos de los peajes sin afectar su funcionamiento, empleando predicci√≥n mediante modelos de machine learning. Dado que la predicci√≥n de 30 d√≠as evidencio el ahorro en operaci√≥n se cumple el objetivo de validar que es posible la reducci√≥n de costos de operacion.  

¬øCu√°les fueron las mayores dificultades que se obtuvieron durante su Desarrollo? 

El prop√≥sito central del proyecto fue identificar alternativas para reducir los costos operativos de los peajes sin comprometer su funcionamiento, utilizando modelos de predicci√≥n basados en machine learning. Los resultados obtenidos en la proyecci√≥n a 30 d√≠as demostraron que es posible anticipar el comportamiento del flujo vehicular con suficiente precisi√≥n para optimizar la asignaci√≥n de recursos operativos. Esto permiti√≥ validar que la reducci√≥n de costos es alcanzable sin afectar la operaci√≥n, cumpliendo as√≠ el objetivo planteado. 

¬øQu√© estimaci√≥n se puede dar respecto a c√≥mo se impactar√≠an las m√©tricas de negocio (KPIs) una vez el producto de datos sea utilizado por usuarios reales? 

La adopci√≥n del producto de datos por parte de los usuarios operativos tendr√≠a un impacto directo y medible sobre los principales KPIs del sistema de peajes. En primer lugar, al permitir anticipar con 30 d√≠as de antelaci√≥n el flujo vehicular por estaci√≥n y sentido, se optimiza la asignaci√≥n de personal y la habilitaci√≥n de carriles, lo que se traduce en una reducci√≥n significativa de los costos operativos asociados a turnos, horas extra y sobredimensionamiento de recursos. En segundo lugar, una operaci√≥n m√°s eficiente contribuye a mejorar indicadores como el nivel de servicio, ya que se mitigan congestiones, tiempos de espera prolongados y cierres innecesarios de carriles. 

Adicionalmente, el uso sistem√°tico de predicciones precisas permite mejorar la planificaci√≥n presupuestal, evitando sobrecostos por decisiones reactivas y favoreciendo la toma de decisiones basada en datos. Tambi√©n se espera un impacto positivo en la eficiencia operativa global, dado que los recursos son asignados donde realmente se necesitan seg√∫n patrones hist√≥ricos y proyectados. Finalmente, la correcta implementaci√≥n del producto de datos puede favorecer KPIs estrat√©gicos como la satisfacci√≥n del usuario, la disponibilidad operativa y la confiabilidad del servicio, consolidando un modelo de operaci√≥n m√°s sostenible y basado en anal√≠tica avanzada. 

¬øQu√© condiciones considera que deber√≠an tener los datos para obtener mejores resultados? M√°s datos, nuevas caracter√≠sticas, menor sesgo, etc.  

Para incrementar la precisi√≥n y robustez de los modelos predictivos desarrollados, ser√≠a fundamental contar con datos que cumplan varias condiciones clave: 

Mayor volumen y continuidad temporal 
Los modelos de series de tiempo se benefician fuertemente de series largas, estables y sin interrupciones. Contar con varios a√±os adicionales sin vac√≠os de informaci√≥n permitir√≠a capturar mejor patrones estacionales, efectos recurrentes y variabilidad interanual. 

Datos m√°s limpios y coherentes 
La presencia de ceros artificiales o valores at√≠picos generados por fallas de registro afecta la se√±al real del tr√°fico vehicular. Contar con datos sin ruido operativo y con un proceso riguroso de control de calidad mejorar√≠a directamente el ajuste del modelo. 

Nuevas caracter√≠sticas (features) relevantes 
Incorporar variables externas con relaci√≥n causal al tr√°fico puede mejorar sustancialmente el poder predictivo. Entre ellas: 

Festivos, puentes y calendarios locales m√°s detallados 

Clima (lluvia, temperatura, visibilidad) 

Eventos especiales o cierres viales 

TRM, combustibles, comportamientos estacionales regionales 

Datos de sensores adicionales como densidad, velocidad o clasificaci√≥n detallada del veh√≠culo 

Menor sesgo por cambios operativos 
Algunas estaciones presentan quiebres abruptos en la serie debido a obras, cierres o momentos donde el contador dej√≥ de funcionar. Series m√°s homog√©neas o con marcas claras de los eventos permitir√≠an a los modelos aprender con consistencia y evitar rupturas que afectan la generalizaci√≥n. 

Mejor granularidad operacional 
Datos por carril, por categor√≠a de veh√≠culo o por intervalos de tiempo m√°s peque√±os (por ejemplo, cada hora) permitir√≠an modelos m√°s finos y 

explicativos, adem√°s de facilitar estimaciones m√°s precisas para la toma de decisiones diarias. 

Mayor representatividad para casos extremos (picos y valles) 
Los modelos muestran un mayor error cuando deben predecir d√≠as altamente at√≠picos. Tener m√°s ejemplos de esos escenarios ayudar√≠a a capturar mejor su comportamiento y reducir errores futuros. 

¬øEl mejor modelo obtenido es suficiente para dar soluci√≥n al problema u oportunidad de negocio abordado? 

El mejor modelo obtenido s√≠ aporta una base s√≥lida para abordar el problema de negocio, ya que demuestra que es posible predecir el flujo vehicular con una precisi√≥n suficiente para soportar decisiones operativas, especialmente las relacionadas con la programaci√≥n de personal y habilitaci√≥n de carriles, que son el principal costo operativo de los peajes. 

En t√©rminos pr√°cticos, el modelo permite anticipar la demanda con 30 d√≠as de anterioridad, lo que habilita escenarios como: 

Optimizar turnos de operaci√≥n, reduciendo horas hombre en d√≠as de baja demanda. 

Habilitar √∫nicamente los carriles necesarios, disminuyendo costos sin afectar el nivel de servicio. 

Planificar mantenimientos o cierres parciales en d√≠as proyectados con menor flujo. Sin embargo, aunque el modelo es funcional y demuestra valor, no es a√∫n la versi√≥n definitiva del producto de datos. Existen estaciones con comportamiento m√°s complejo donde el error es mayor (por ejemplo, La Parada sentido 2), lo cual indica la necesidad de: Incluir variables externas m√°s relevantes (clima, eventos, cierres viales). 

Mejorar la calidad y continuidad de las series hist√≥ricas. 

Ajustar modelos personalizados por estaci√≥n con arquitectura m√°s flexible. 

En conclusi√≥n: 
El modelo actual es suficiente para demostrar viabilidad y generar ahorros operativos reales, pero requiere iteraciones adicionales para convertirse en un producto de datos robusto, escalable y apto para implementaci√≥n en producci√≥n. 


